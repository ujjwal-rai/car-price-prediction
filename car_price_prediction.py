# -*- coding: utf-8 -*-
"""car-price-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CuTELbFuxnbjPs0YGHijsdyakrUYcs2a
"""

# prompt: write code to open train.csv file using pandas
import numpy as np
import pandas as pd
df = pd.read_csv("car_price_prediction.csv")

# prompt: show first five rows of train data
df

# prompt: .info
df.info()

# prompt: remove the column Doors, Wheel, Color, Levy, ID
df = df.drop(['Doors', 'Wheel', 'Color', 'Levy', 'ID'], axis=1)
df

# missing values
df.isnull().sum()

# check for duplicate values
df.duplicated().sum()

# remove duplicates
df = df.drop_duplicates(keep='first')

df.shape

df.head()

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

# prompt: replace - in any column with None
df = df.replace('-', None)

df.info()

df['Category'] = encoder.fit_transform(df['Category'])
df['Leather interior'] = encoder.fit_transform(df['Leather interior'])
df['Drive wheels'] = encoder.fit_transform(df['Drive wheels'])
df['Fuel type'] = encoder.fit_transform(df['Fuel type'])
df['Gear box type'] = encoder.fit_transform(df['Gear box type'])
df['Model'] = encoder.fit_transform(df['Model'])
df['Manufacturer'] = encoder.fit_transform(df['Manufacturer'])

df

df.info()

# prompt: make an another column of turbo if turbo found in Engine volume column take it 1 else 0 and remove turbo from Engine volume and make it float64
df['Turbo'] = df['Engine volume'].str.contains('Turbo').astype(int)
df['Engine volume'] = df['Engine volume'].str.replace('Turbo', '').astype(float)
df.info()

df

df['Mileage'] = df['Mileage'].str.replace('km', '').astype('int64')
df.info()

# Separate features (X) and target (y)
X = df.drop('Price', axis=1)
y = df['Price']

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

# Choose a regression model (e.g., Linear Regression, Random Forest, Gradient Boosting)
from sklearn.linear_model import LinearRegression
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score

# Evaluate the model's performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Actual Price vs. Predicted Price")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Add a diagonal line for reference
plt.show()

# Try different regression models
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# 1. Random Forest Regression
rf_model = RandomForestRegressor(random_state=2)
rf_model.fit(X_train, y_train)
rf_y_pred = rf_model.predict(X_test)
rf_mse = mean_squared_error(y_test, rf_y_pred)
rf_r2 = r2_score(y_test, rf_y_pred)
print(f"Random Forest - Mean Squared Error: {rf_mse}")
print(f"Random Forest - R-squared: {rf_r2}")

# 2. Gradient Boosting Regression
gb_model = GradientBoostingRegressor(random_state=2)
gb_model.fit(X_train, y_train)
gb_y_pred = gb_model.predict(X_test)
gb_mse = mean_squared_error(y_test, gb_y_pred)
gb_r2 = r2_score(y_test, gb_y_pred)
print(f"Gradient Boosting - Mean Squared Error: {gb_mse}")
print(f"Gradient Boosting - R-squared: {gb_r2}")


# 2. Feature Engineering:
# * Create new features that might be more relevant to the price.
# * Consider interaction terms between existing features.
# * Use domain knowledge to identify features that could be important.
# Example:
# df['Engine_Mileage_Ratio'] = df['Engine volume'] / df['Mileage']

# 3. Hyperparameter Tuning:
# * Use techniques like Grid Search or Randomized Search to find the best hyperparameters
# * Example for RandomForest:
# from sklearn.model_selection import GridSearchCV
# param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}
# grid_search = GridSearchCV(RandomForestRegressor(random_state=2), param_grid, cv=5)
# grid_search.fit(X_train, y_train)
# best_rf_model = grid_search.best_estimator_
# best_rf_y_pred = best_rf_model.predict(X_test)
# best_rf_mse = mean_squared_error(y_test, best_rf_y_pred)
# best_rf_r2 = r2_score(y_test, best_rf_y_pred)
# print(f"Best Random Forest - Mean Squared Error: {best_rf_mse}")
# print(f"Best Random Forest - R-squared: {best_rf_r2}")

# 4. Data Scaling or Normalization:
# from sklearn.preprocessing import StandardScaler
# scaler = StandardScaler()
# X_train = scaler.fit_transform(X_train)
# X_test = scaler.transform(X_test)

# 5. Regularization (for linear models):
# from sklearn.linear_model import Ridge, Lasso
# ridge_model = Ridge(alpha=1.0)
# lasso_model = Lasso(alpha=1.0)

# 6. Cross-Validation:
# Use k-fold cross-validation to get a more robust estimate of model performance.

# 7. Outlier Detection and Treatment:
# Identify and handle outliers in your data, as they can significantly impact model performance.

import matplotlib.pyplot as plt

# ... (Your existing code for model training and prediction) ...


# Create a figure with two subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot for Random Forest
axes[0].scatter(y_test, rf_y_pred, alpha=0.5)
axes[0].set_xlabel("Actual Price")
axes[0].set_ylabel("Predicted Price")
axes[0].set_title("Random Forest: Actual Price vs. Predicted Price")
axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)

# Plot for Gradient Boosting
axes[1].scatter(y_test, gb_y_pred, alpha=0.5)
axes[1].set_xlabel("Actual Price")
axes[1].set_ylabel("Predicted Price")
axes[1].set_title("Gradient Boosting: Actual Price vs. Predicted Price")
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)


plt.tight_layout()  # Adjust subplot parameters for a tight layout
plt.show()

# The dotted line in the scatter plots represents the ideal scenario where the predicted values are perfectly equal to the actual values.
# In other words, it depicts a perfect prediction where the model is able to accurately predict the price for every data point.
# It serves as a visual reference to assess the model's performance, indicating how well the model's predictions align with the true values.
# The closer the data points are to the dotted line, the better the model's predictions.

# There's no single "acceptable" MSE value, as it depends heavily on the context of your problem and the scale of your target variable (price in this case).
# However, we can interpret it relative to the variance of your target variable.
# A good rule of thumb is that your MSE should be significantly smaller than the variance of your target variable.

# Let's calculate the variance of the target variable:
y_variance = y.var()
print(f"Variance of the target variable (Price): {y_variance}")

# Compare the MSE of your models to this variance:
# If the MSE is much smaller (e.g., less than 10-20% of the variance),
# it indicates that your model is performing relatively well in capturing the variance in the data.

# Example using the Random Forest MSE:
print(f"Random Forest - Mean Squared Error: {rf_mse}")
mse_relative_to_variance = rf_mse / y_variance
print(f"MSE relative to variance: {mse_relative_to_variance}")


# In general, a lower MSE is desirable, but the "acceptable" level depends on your specific needs.
# Here are some things to consider:
# * The scale of your target variable (price): A MSE of 1000 might be good if the prices are in the millions, but bad if the prices are in the hundreds.
# * The complexity of your problem: Some problems are inherently more difficult to predict than others.
# * The purpose of your model: If you need very accurate predictions, you'll need a lower MSE than if you just need a general idea.

# You can also compare the MSE of your models to the baseline MSE that you would get if you always predicted the mean of your target variable.
# If your model's MSE is significantly lower than the baseline MSE, then it's likely performing well.

# Ultimately, the "acceptable" MSE is something that you need to determine based on your specific needs and the context of your problem.

# prompt: using import pickle download model.pkl and vectorizer.pkl of just trained model

import pickle

# Assuming you have trained your model (e.g., rf_model) and want to save it
# Replace 'rf_model' with the actual variable name of your trained model.
# You can also save other objects like your feature scaler or encoder if needed.

# Save the model
filename = 'model.pkl'
pickle.dump(rf_model, open(filename, 'wb'))

# If you have a fitted LabelEncoder or StandardScaler, you can save it similarly:
# filename_encoder = 'vectorizer.pkl'
# pickle.dump(encoder, open(filename_encoder, 'wb'))

# To load the model later:
# with open('model.pkl', 'rb') as file:
#     loaded_model = pickle.load(file)

# To use the loaded model for predictions:
# predictions = loaded_model.predict(X_test)

